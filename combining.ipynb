{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fe0210-7ee4-4bc4-ba3f-80e9254ee274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import globh\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f51338a-1ad9-4767-bd14-914797272f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths=glob.glob('/Users/karolina/Desktop/oc/AREX2022netcdf/*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ad108f-996a-404b-92d2-66410dbbb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[xr.open_dataset(fp) for fp in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a85373a2-2886-4438-9462-8e48eb21a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_levels=max(ds.sizes.get('n_levels', 0) for ds in datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57a6db86-3ff5-48e5-9fa1-6d00f68790ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_datasets=[\n",
    "    ds.pad(n_levels=(0, max_levels-ds.sizes.get('n_levels', 0)), constant_values=np.nan)\n",
    "    if 'n_levels' in ds.sizes else ds\n",
    "    for ds in datasets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff1c7ccd-b80e-449d-89d8-45182f167ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_names=[\n",
    "    ds.attrs.get('station_name', f\"Station_{i+1}\") for i, ds in enumerate(aligned_datasets)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9050880-d673-4f95-a55d-f033667dcacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds=xr.concat(aligned_datasets, dim='station', join='outer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9abe667f-6615-4723-bceb-e2e555fcb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars=['ptemp', 'psal', 'latitude', 'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9d591c8-be1a-4429-8dc6-4a3c0809c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_datasets=[ds[selected_vars] for ds in aligned_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fc73f13-dd6b-4442-bae6-ab998e27876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ds in enumerate(filtered_datasets):\n",
    "    ds.coords['station']=station_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9806bac9-d394-401b-8bf5-9807782510c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds=xr.concat(filtered_datasets, dim='station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f701e6e0-2bfb-4cff-9d16-352eaed289e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: HDF error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m combined_ds\u001b[38;5;241m.\u001b[39mto_netcdf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/users/karolina/desktop/o.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/xarray/core/dataset.py:2372\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2370\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_netcdf(  \u001b[38;5;66;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001b[39;00m\n\u001b[1;32m   2373\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2374\u001b[0m     path,\n\u001b[1;32m   2375\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   2376\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[1;32m   2377\u001b[0m     group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[1;32m   2378\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m   2379\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   2380\u001b[0m     unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims,\n\u001b[1;32m   2381\u001b[0m     compute\u001b[38;5;241m=\u001b[39mcompute,\n\u001b[1;32m   2382\u001b[0m     multifile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2383\u001b[0m     invalid_netcdf\u001b[38;5;241m=\u001b[39minvalid_netcdf,\n\u001b[1;32m   2384\u001b[0m     auto_complex\u001b[38;5;241m=\u001b[39mauto_complex,\n\u001b[1;32m   2385\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/xarray/backends/api.py:1873\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# TODO: figure out how to refactor this logic (here and in save_mfdataset)\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# to avoid this mess of conditionals\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1871\u001b[0m     \u001b[38;5;66;03m# TODO: allow this work (setting up the file for writing array data)\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m     \u001b[38;5;66;03m# to be parallelized with dask\u001b[39;00m\n\u001b[0;32m-> 1873\u001b[0m     dump_to_store(\n\u001b[1;32m   1874\u001b[0m         dataset, store, writer, encoding\u001b[38;5;241m=\u001b[39mencoding, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims\n\u001b[1;32m   1875\u001b[0m     )\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m autoclose:\n\u001b[1;32m   1877\u001b[0m         store\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/xarray/backends/api.py:1920\u001b[0m, in \u001b[0;36mdump_to_store\u001b[0;34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder:\n\u001b[1;32m   1918\u001b[0m     variables, attrs \u001b[38;5;241m=\u001b[39m encoder(variables, attrs)\n\u001b[0;32m-> 1920\u001b[0m store\u001b[38;5;241m.\u001b[39mstore(variables, attrs, check_encoding, writer, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/xarray/backends/common.py:451\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.store\u001b[0;34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_attributes(attributes)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_dimensions(variables, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims)\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_variables(\n\u001b[1;32m    452\u001b[0m     variables, check_encoding_set, writer, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims\n\u001b[1;32m    453\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/xarray/backends/common.py:493\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.set_variables\u001b[0;34m(self, variables, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[1;32m    488\u001b[0m check \u001b[38;5;241m=\u001b[39m vn \u001b[38;5;129;01min\u001b[39;00m check_encoding_set\n\u001b[1;32m    489\u001b[0m target, source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_variable(\n\u001b[1;32m    490\u001b[0m     name, v, check, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims\n\u001b[1;32m    491\u001b[0m )\n\u001b[0;32m--> 493\u001b[0m writer\u001b[38;5;241m.\u001b[39madd(source, target)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/xarray/backends/common.py:338\u001b[0m, in \u001b[0;36mArrayWriter.add\u001b[0;34m(self, source, target, region)\u001b[0m\n\u001b[1;32m    336\u001b[0m     target[region] \u001b[38;5;241m=\u001b[39m source\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     target[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m source\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:82\u001b[0m, in \u001b[0;36mBaseNetCDF4Array.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m     81\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 82\u001b[0m     data[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mautoclose:\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mclose(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5630\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__setitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5917\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable._put\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2164\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: HDF error"
     ]
    }
   ],
   "source": [
    "combined_ds.to_netcdf('/users/karolina/desktop/o.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2199627-3703-458a-a929-2c02c17e4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds.attrs={}\n",
    "for var in combined_ds.data_vars:\n",
    "    combined_ds[var].attrs={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b19313b-e483-4057-9649-d08224122a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 4GB\n",
      "Dimensions:    (station: 251, time: 251, n_levels: 3631)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2kB 2022-06-20T10:48:54 ... 2022-07-27T0...\n",
      "  * station    (station) <U7 7kB 'Z1' 'N0' 'K7' 'WB11' ... 'WB3' 'V33' 'Y6' 'H5'\n",
      "Dimensions without coordinates: n_levels\n",
      "Data variables:\n",
      "    ptemp      (station, time, n_levels) float64 2GB nan nan nan ... nan nan nan\n",
      "    psal       (station, time, n_levels) float64 2GB nan nan nan ... nan nan nan\n",
      "    latitude   (station, time) float64 504kB nan nan nan nan ... nan nan nan nan\n",
      "    longitude  (station, time) float64 504kB nan nan nan nan ... nan nan nan nan\n"
     ]
    }
   ],
   "source": [
    "print(combined_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe46aff-22f7-44c9-8dc3-7281db954759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
